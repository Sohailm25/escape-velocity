\documentclass[11pt]{article}

% === Packages ===
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{xcolor}
% \usepackage{multirow}  % not available in TinyTeX

% === Title ===
\title{Depth-Dynamics Signatures of Conversational Collapse:\\
Finite-Time Lyapunov Analysis of Transformer Forward Passes}
\author{
  Sohail Mohammad \\
  Independent Researcher \\
  \texttt{sohailmo.ai@gmail.com}
}
\date{February 2026}

\begin{document}
\maketitle

\begin{abstract}
We estimate the top-1 finite-time Lyapunov exponent ($\lambda_1$) for transformer depth dynamics using forward-mode automatic differentiation (JVP-based tangent propagation) with QR renormalization, and test whether depth-dynamics summaries are associated with conversational collapse behavior observed in multi-turn self-play. Across 720 preregistered trajectories (4 conditions $\times$ 36 seeds $\times$ 5 repeats) and 7{,}200 FTLE computations on three 7B-parameter model families, we observe that $\lambda_1$ \emph{profile features}---specifically the depth-profile slope ($\rho = -0.536$) and layerwise variance ($\rho = +0.511$)---show medium-to-large associations with collapse metrics from Escape Velocity. Mean $\lambda_1$ alone shows only weak association ($|\rho| \leq 0.25$). Three of six preregistered Spearman correlations pass the effect-size threshold ($|\rho| \geq 0.40$, Bonferroni--Holm adjusted $p < 0.05$), meeting the preregistered success criterion. However, the 720-row analysis contains only 108 unique $\lambda_1$ predictor vectors (36 seeds $\times$ 3 distinct models), so nominal $p$-values are anti-conservative and effect-size magnitudes should be treated as the primary evidence. We interpret this as exploratory support for a bridge hypothesis, not confirmatory relationship establishment. All findings are predictive associations; no causal or mechanistic identity is claimed. Escape Velocity collapse labels have unconfirmed inter-rater reliability ($\kappa = 0.566$, threshold $0.80$ not met), and this caveat applies to all bridge correlations.
\end{abstract}

\section{Introduction}

Transformer language models process input through a sequence of residual-stream updates across layers. This depth-wise computation can be viewed as a discrete dynamical system \citep{chen2018neural}: each layer maps the hidden state to a new state, accumulating nonlinear transformations. The sensitivity of this process to perturbations---quantified by Lyapunov exponents \citep{eckmann1985ergodic,wolf1985determining}---provides a model-intrinsic characterization of how information is amplified or suppressed during a forward pass.

Separately, multi-turn self-play between language models exhibits \emph{conversational collapse}: a progressive loss of output novelty where models become trapped in repetitive response patterns \citep{holtzman2019curious,welleck2020neural,li2016diversity}. Escape Velocity characterized collapse dynamics across four interaction conditions using 7B-parameter models, achieving full confirmatory closure (720/720 trajectories) but not meeting its preregistered detector reliability threshold ($\kappa = 0.566$; threshold $0.80$).

This paper asks whether the depth dynamics of a single forward pass---specifically, the top-1 finite-time Lyapunov exponent ($\lambda_1$)---are associated with the across-turn collapse behavior documented in Escape Velocity. This is a \emph{predictive association} hypothesis: we test whether models whose depth dynamics exhibit certain profile features tend to collapse more in extended conversations. We do not claim causal or mechanistic identity between within-pass depth dynamics and across-turn conversational dynamics, as these operate on fundamentally different time axes.

The primary contributions are: (1)~a computationally feasible FTLE profiling pipeline for production-scale transformers; (2)~preregistered evidence of observed conditional associations between depth-profile features and collapse metrics; and (3)~transparent documentation of the structural limitations (predictor non-independence, inherited label uncertainty) that constrain inferential strength.

\section{Methods}

\subsection{FTLE estimator}

Let $F_l$ denote the residual-stream update at layer $l$ for a fixed token-context state. The local Jacobian $J_l = \partial F_l / \partial h_l$ characterizes sensitivity at each layer. Rather than computing full Jacobians (prohibitive for $d_{\text{model}} = 4096$), we use forward-mode automatic differentiation (JVP) \citep{baydin2018automatic} to propagate tangent vectors through the layer stack.

Given an initial tangent vector $v_0$, the tangent product $P_L v_0 = J_L \cdots J_2 J_1 v_0$ is computed via a single forward pass with \texttt{torch.func.jvp}. To prevent numerical overflow across 32 layers, we apply QR-based renormalization at a cadence of 4 layers (locked from Phase~1 pilot):

\begin{equation}
\lambda_1 = \frac{1}{L} \sum_{k=1}^{L/c} \log \|v_{kc}\| \quad \text{where } v_{kc} \text{ is renormalized every } c=4 \text{ layers.}
\end{equation}

For each trajectory, we compute $\lambda_1$ using 10 random tangent seeds (seeds 0--9) and report the mean across seeds. The layerwise $\lambda_1$ profile (log growth rate at each layer) captures the \emph{shape} of sensitivity across depth.

\subsection{Computation details}

\begin{itemize}
    \item \textbf{Token position:} Mean over all assistant tokens in the first turn.
    \item \textbf{Precision:} float32 throughout (locked after Phase~0 dtype transfer analysis showing float64 $\leftrightarrow$ float32 $r = 0.788$; precisions are not interchangeable).
    \item \textbf{RoPE handling:} Non-GPT2 models (Llama, Qwen, Mistral) require explicit \texttt{position\_embeddings} through JVP; fixed during Phase~0.
    \item \textbf{Flash attention:} Forced MATH SDPA backend (flash attention lacks forward-mode AD support).
    \item \textbf{Hardware:} Modal A100-80GB, max 2 concurrent containers per model.
\end{itemize}

\subsection{Models and conditions}

\begin{table}[h]
\centering
\caption{Model-to-condition mapping (locked from Escape Velocity).}
\label{tab:models}
\begin{tabular}{llc}
\toprule
Condition & Model & FTLE calls \\
\midrule
HOMO\_A & meta-llama/Llama-3.1-8B-Instruct (rev \texttt{0e9e39f2}) & 1{,}800 \\
HOMO\_B & Qwen/Qwen2.5-7B-Instruct (rev \texttt{a09a3545}) & 1{,}800 \\
HOMO\_C & mistralai/Mistral-7B-Instruct-v0.3 (rev \texttt{c170c708}) & 1{,}800 \\
HETERO\_ROT & meta-llama/Llama-3.1-8B-Instruct (rev \texttt{0e9e39f2}) & 1{,}800 \\
\bottomrule
\end{tabular}
\end{table}

HETERO\_ROT uses the first assistant model (Llama) for FTLE computation. HOMO\_A and HETERO\_ROT therefore produce identical $\lambda_1$ distributions, as FTLE depends only on (model, prompt, tangent seed, cadence).

\subsection{Bridge analysis}

Six preregistered Spearman rank correlations between three $\lambda_1$ summaries and two Escape Velocity collapse metrics:

\begin{itemize}
    \item \textbf{$\lambda_1$ summaries:} mean $\lambda_1$, layerwise profile variance, depth-profile slope.
    \item \textbf{Escape Velocity metrics:} collapse rate, first collapse turn (censored at 40 for non-collapsing), collapse incidence.
\end{itemize}

Multiple comparison correction: Bonferroni--Holm step-down across 6 tests, family $\alpha = 0.05$. Confidence intervals: bias-corrected bootstrap percentile (10{,}000 resamples, seed 42). Success criterion: $\geq 1$ test with $|\rho| \geq 0.40$ and Holm-adjusted $p < 0.05$.

Sensitivity analysis repeated on the 167-window rater-agreed subset from Escape Velocity reliability audit.

\section{Results}

\subsection{Phase 2 execution}

All 7{,}200 FTLE calls completed with zero attrition (0 NaN/Inf, 0 failures). Wall time: 23.4 minutes. Estimated cost: \$20 (well under \$500 cap).

\subsection{Bridge correlations}

\begin{table}[h]
\centering
\caption{Primary bridge results ($n = 720$). Prereg threshold: $|\rho| \geq 0.40$, Holm $p < 0.05$.}
\label{tab:primary}
\begin{tabular}{clllccl}
\toprule
\# & $\lambda_1$ summary & Escape Velocity metric & $\rho$ & $p_{\text{Holm}}$ & 95\% CI & Pass \\
\midrule
1 & mean & collapse rate & $+0.246$ & $4.26 \times 10^{-11}$ & $[+0.17, +0.32]$ & \texttimes \\
2 & mean & first collapse turn & $-0.251$ & $2.29 \times 10^{-11}$ & $[-0.32, -0.18]$ & \texttimes \\
3 & mean & collapse incidence & $+0.036$ & $0.337$ & $[-0.03, +0.10]$ & \texttimes \\
4 & \textbf{variance} & \textbf{collapse rate} & $\mathbf{+0.511}$ & $\mathbf{2.41 \times 10^{-48}}$ & $[+0.45, +0.57]$ & \checkmark \\
5 & \textbf{slope} & \textbf{collapse rate} & $\mathbf{-0.536}$ & $\mathbf{5.24 \times 10^{-54}}$ & $[-0.59, -0.48]$ & \checkmark \\
6 & \textbf{slope} & \textbf{first collapse turn} & $\mathbf{+0.507}$ & $\mathbf{1.22 \times 10^{-47}}$ & $[+0.45, +0.56]$ & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

Three of six tests pass: Tests \#4, \#5, and \#6. The preregistered success criterion ($\geq 1$ pass) is \textbf{met}. The effect-size magnitudes ($|\rho| = 0.51$--$0.54$) are the primary evidence; the reported $p$-values are nominal and likely anti-conservative due to predictor non-independence (see Limitations). We interpret this as exploratory support for the bridge hypothesis under this protocol, not confirmatory relationship establishment or mechanistic validation.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{figures/figure_1_bridge_heatmap.pdf}
\caption{Bridge correlation heatmap. Checkmarks indicate tests meeting the preregistered threshold ($|\rho| \geq 0.40$, Holm $p < 0.05$). All correlations are subject to the Escape Velocity label reliability caveat ($\kappa = 0.566$).}
\label{fig:heatmap}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures/figure_2_passing_scatters.pdf}
\caption{Scatter plots for the three passing tests. Colors indicate experimental conditions. Predictive associations only---no causal claims.}
\label{fig:scatters}
\end{figure}

\subsection{Sensitivity analysis}

\begin{table}[h]
\centering
\caption{Sensitivity analysis ($n = 167$ rater-agreed subset).}
\label{tab:sensitivity}
\begin{tabular}{cllccl}
\toprule
\# & $\lambda_1$ summary & Escape Velocity metric & $\rho$ & $p_{\text{Holm}}$ & Pass \\
\midrule
1 & mean & collapse rate & $+0.255$ & $1.75 \times 10^{-3}$ & \texttimes \\
2 & mean & first collapse turn & $-0.265$ & $1.64 \times 10^{-3}$ & \texttimes \\
3 & mean & collapse incidence & $-0.005$ & $0.947$ & \texttimes \\
4 & \textbf{variance} & \textbf{collapse rate} & $\mathbf{+0.545}$ & $\mathbf{1.39 \times 10^{-13}}$ & \checkmark \\
5 & \textbf{slope} & \textbf{collapse rate} & $\mathbf{-0.557}$ & $\mathbf{3.15 \times 10^{-14}}$ & \checkmark \\
6 & \textbf{slope} & \textbf{first collapse turn} & $\mathbf{+0.516}$ & $\mathbf{3.86 \times 10^{-12}}$ & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

The same three tests pass in the sensitivity analysis, with consistent effect sizes (within CIs of the primary analysis).

\subsection{Depth profiles}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{figures/figure_3_depth_profiles.pdf}
\caption{Mean $\lambda_1$ depth profiles by condition. The shape differences (slope, variance) drive the observed associations with collapse behavior.}
\label{fig:profiles}
\end{figure}

\section{Protocol corrections}

Two deviations from PREREG\_v2.md were identified and corrected before results were finalized:

\begin{enumerate}
    \item \textbf{Test \#4 variable mapping:} Initially used \texttt{lambda1\_std} (tangent-seed standard deviation). Corrected to \texttt{layerwise\_variance\_mean} (layerwise profile variance) per the preregistered definition. This changed $\rho$ from $-0.059$ to $+0.511$ and promoted Test~\#4 from fail to pass.
    \item \textbf{first\_collapse\_turn missingness:} Initially excluded non-collapsing runs ($n = 540$). Corrected to censor at turn~40 per the preregistered specification ($n = 720$). Test~\#6 attenuated slightly ($\rho$: $0.539 \to 0.507$) but still passed.
\end{enumerate}

Full before/after comparison is documented in \texttt{DEVIATION\_TABLE.md}. The fact that Test~\#4 changed from fail to pass on correction warrants additional interpretive caution.


\subsection{Candidate mechanisms (speculative)}
The observed association between depth-profile features and collapse susceptibility is consistent with at least two broad hypotheses, neither of which is tested here:
\begin{itemize}
    \item \textbf{Sensitivity compression:} Models whose depth dynamics concentrate sensitivity in early layers (steep negative slope) may have less capacity to differentiate contextually diverse inputs in later layers, producing more homogeneous outputs over extended interaction.
    \item \textbf{Architectural confound:} The three model families differ in architecture, training data, and alignment procedures. The observed $\lambda_1$ profile differences may reflect these model-level properties rather than a generalizable relationship between depth dynamics and collapse behavior. A within-model-family test (varying prompts or conditions while holding model constant) would be needed to distinguish these explanations; such a test is not available in the current design because each model family appears in only one or two conditions.
\end{itemize}
These remain hypotheses for follow-up investigation, not conclusions of the present study.

\subsection{What this does not show}
These results do not establish a causal mechanism linking within-forward-pass depth dynamics to across-turn conversational collapse. They also do not guarantee transfer beyond the tested model families and protocol choices. Finally, bridge effect sizes remain bounded by the Escape Velocity label-reliability limitation ($\kappa=0.566$).

\section{Limitations}

\paragraph{Escape Velocity label reliability.} All bridge correlations use Escape Velocity collapse labels with unconfirmed inter-rater reliability ($\kappa = 0.566$, threshold $0.80$ not met; raw agreement 92.8\%). Effect sizes may be attenuated or inflated by label noise. The sensitivity analysis on 167 rater-agreed windows provides a partial check but not a full resolution.

\paragraph{Predictive association, not causation.} $\lambda_1$ depth dynamics and conversational collapse operate on fundamentally different time axes (within-forward-pass vs.\ across-turn). The observed correlations indicate predictive association; no causal mechanism is established.

\paragraph{Mean $\lambda_1$ insufficiency.} Three of six tests failed because mean $\lambda_1$ showed only weak associations ($|\rho| \leq 0.25$). The \emph{shape} of the depth profile matters more than its average level.

\paragraph{Model family confound.} HOMO\_A and HETERO\_ROT produce identical $\lambda_1$ distributions (both use Llama-3.1-8B). Between-model $\lambda_1$ variation may partially reflect architectural differences rather than a generalizable relationship.

\paragraph{Predictor dependence structure.} HOMO\_A and HETERO\_ROT share the same model and seed prompts, producing identical $\lambda_1$ values for matched seeds. Additionally, within each condition, the five repeat trajectories per seed share identical $\lambda_1$ values (FTLE depends only on model, prompt, tangent seed, and cadence). Consequently, the 720-row bridge analysis contains only 108 unique $\lambda_1$ vectors (36 seeds $\times$ 3 distinct models), each repeated across multiple rows with different Escape Velocity collapse outcomes. The within-cluster collapse variance drives the observed correlations, but the non-independence of the predictor means effective degrees of freedom are lower than the nominal $n = 720$. Standard errors are likely underestimated and the reported $p$-values and confidence intervals should be interpreted as anti-conservative. The preregistered protocol specified $n = 720$ with these conditions, so we report the planned analysis but flag this structural dependence as a limitation on inferential precision.

\paragraph{Precision sensitivity.} Float64 and float32 $\lambda_1$ estimates are not interchangeable ($r = 0.788$). All production runs used float32 consistently.

\paragraph{Single first-turn measurement.} $\lambda_1$ is computed on the first assistant turn only. A longitudinal study computing $\lambda_1$ at each turn could provide stronger evidence but was out of scope.

\section{Conclusion}

We observe that $\lambda_1$ \emph{profile features}---depth-profile slope and layerwise variance---show medium-to-large associations with multi-turn collapse behavior ($|\rho| = 0.51$--$0.54$) across three 7B-parameter model families. Mean $\lambda_1$ alone is insufficient. These results are consistent with the hypothesis that the shape of a model's depth-dynamics sensitivity profile is informative about collapse susceptibility, but the evidence is exploratory rather than confirmatory: the predictor dependence structure (108 unique vectors across 720 rows) means nominal $p$-values overstate statistical certainty, and the between-model-family design cannot distinguish depth-dynamics effects from model-level confounds.

The primary durable contribution is the FTLE profiling pipeline itself: a computationally tractable, numerically stable method for estimating depth-dynamics sensitivity in production-scale transformers (\$20 for 7,200 calls). The bridge evidence provides a testable direction for future work, not a confirmed relationship.

All findings carry the Escape Velocity label reliability caveat ($\kappa = 0.566$) and are restricted to observed associations under the tested protocol. The highest-priority follow-ups are: (1)~human-rater reliability validation for Escape Velocity labels; (2)~dependency-aware inference (e.g., clustered bootstrap at the seed$\times$model level); and (3)~within-model-family tests using diverse prompt sets to separate model-level from prompt-level variation.

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
